{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180fa13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "import DA_methods\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri\n",
    "import numpy as np\n",
    "from L96_model import L96, L96_eq1_xdot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b06a16",
   "metadata": {},
   "source": [
    "This notebook is a stripped-down copy of the notebook in `03Data-Assimilation` directory and altered the parameters of the Lorenz 1996 model to match those of Wilks, 2005.\n",
    "- For the purposes of this illustration, we removed all the unused options and parameters in the DA algorithm.\n",
    "- The L96 model here uses K=8, J=32, F=18, as in Wilks, 2005."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4381b552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducibility\n",
    "rng = np.random.default_rng(3210)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1512941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to represent the GCM, and many other convenience functions used within the DA algorithm\n",
    "\n",
    "\n",
    "def GCM(X0, F, dt, nt, param=[0]):\n",
    "    time, hist, X = (\n",
    "        dt * np.arange(nt + 1),\n",
    "        np.zeros((nt + 1, len(X0))) * np.nan,\n",
    "        X0.copy(),\n",
    "    )\n",
    "    hist[0] = X\n",
    "\n",
    "    for n in range(nt):\n",
    "        X = X + dt * (L96_eq1_xdot(X, F) - np.polyval(param, X))\n",
    "\n",
    "        hist[n + 1], time[n + 1] = X, dt * (n + 1)\n",
    "    return hist, time\n",
    "\n",
    "\n",
    "def s(k, K):\n",
    "    \"\"\"A non-dimension coordinate from -1..+1 corresponding to k=0..K\"\"\"\n",
    "    return 2 * (0.5 + k) / K - 1\n",
    "\n",
    "\n",
    "def get_dist(i, j, K):\n",
    "    return abs(i - j) if abs(i - j) <= 0.5 * K / 2 else K - abs(i - j)\n",
    "\n",
    "\n",
    "# Generate observation operator, assuming linearity and model space observations\n",
    "def ObsOp(K, l_obs, t_obs, i_t):\n",
    "    nobs = l_obs.shape[-1]\n",
    "    H = np.zeros((nobs, K))\n",
    "    H[range(nobs), l_obs[t_obs == i_t]] = 1\n",
    "    return H\n",
    "\n",
    "\n",
    "# localize covariance matrix based on the Gaspari-Cohn function\n",
    "def cov_loc(B, loc=0):\n",
    "    M, N = B.shape\n",
    "    X, Y = np.ix_(np.arange(M), np.arange(N))\n",
    "    dist = np.vectorize(get_dist)(X, Y, M)\n",
    "    W = np.vectorize(gaspari_cohn)(dist, loc)\n",
    "    return B * W, W\n",
    "\n",
    "\n",
    "def gaspari_cohn(distance, radius):\n",
    "    if distance == 0:\n",
    "        weight = 1.0\n",
    "    else:\n",
    "        if radius == 0:\n",
    "            weight = 0.0\n",
    "        else:\n",
    "            ratio = abs(distance / radius)\n",
    "            weight = 0.0\n",
    "            if ratio <= 1:\n",
    "                weight = (\n",
    "                    -(ratio**5) / 4\n",
    "                    + ratio**4 / 2\n",
    "                    + 5 * ratio**3 / 8\n",
    "                    - 5 * ratio**2 / 3\n",
    "                    + 1\n",
    "                )\n",
    "            elif ratio <= 2:\n",
    "                weight = (\n",
    "                    ratio**5 / 12\n",
    "                    - ratio**4 / 2\n",
    "                    + 5 * ratio**3 / 8\n",
    "                    + 5 * ratio**2 / 3\n",
    "                    - 5 * ratio\n",
    "                    + 4\n",
    "                    - 2 / 3 / ratio\n",
    "                )\n",
    "    return weight\n",
    "\n",
    "\n",
    "def find_obs(loc, obs, t_obs, l_obs, period):\n",
    "    t_period = np.where((t_obs[:, 0] >= period[0]) & (t_obs[:, 0] < period[1]))\n",
    "    obs_period = np.zeros(t_period[0].shape)\n",
    "    obs_period[:] = np.nan\n",
    "    for i in np.arange(len(obs_period)):\n",
    "        if np.any(l_obs[t_period[0][i]] == loc):\n",
    "            obs_period[i] = obs[t_period[0][i]][l_obs[t_period[0][i]] == loc]\n",
    "    return obs_period\n",
    "\n",
    "\n",
    "def running_ave(X, N):\n",
    "    if N % 2 == 0:\n",
    "        N1, N2 = -N / 2, N / 2\n",
    "    else:\n",
    "        N1, N2 = -(N - 1) / 2, (N + 1) / 2\n",
    "\n",
    "    X_sum = np.zeros(X.shape)\n",
    "    for i in np.arange(N1, N2):\n",
    "        X_sum = X_sum + np.roll(X, int(i), axis=0)\n",
    "    return X_sum / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3cca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goldilocks settings\n",
    "config = dict(\n",
    "    K=8,  # Dimension of L96 \"X\" variables\n",
    "    J=32,  # Dimension of L96 \"Y\" variables\n",
    "    obs_freq=10,  # observation frequency (number of sampling intervals (si) per observation)\n",
    "    F_truth=18,  # F for truth signal\n",
    "    F_fcst=18,  # F for forecast (DA) model\n",
    "    GCM_param=np.array(\n",
    "        [0, 0, 0, 0]\n",
    "    ),  # polynomial coefficicents for GCM parameterization\n",
    "    ns_da=4000,  # number of time samples for DA\n",
    "    ns=4000,  # number of time samples for truth signal\n",
    "    ns_spinup=200,  # number of time samples for spin up\n",
    "    dt=0.005,  # model timestep\n",
    "    si=0.005,  # truth sampling interval\n",
    "    B_loc=0.0,  # spatial localization radius for DA\n",
    "    DA=\"EnKF\",  # DA method\n",
    "    nens=50,  # number of ensemble members for DA\n",
    "    inflate_opt=\"relaxation\",  # method for DA model covariance inflation\n",
    "    inflate_factor=0.86,  # inflation factor\n",
    "    obs_density=1.0,  # fraction of spatial gridpoints where observations are collected\n",
    "    DA_freq=10,  # assimilation frequency (number of sampling intervals (si) per assimilation step)\n",
    "    obs_sigma=0.1,  # observational error standard deviation\n",
    "    initial_spread=0.1,  # Initial spread added to initial conditions\n",
    ")\n",
    "\n",
    "# Uncomment blocks below to perturb the above settings\n",
    "\n",
    "# # Less certain observations\n",
    "# config['obs_sigma'] = 1.0\n",
    "# config['initial_spread'] = 1.0\n",
    "# config['inflate_factor'] = 0.5\n",
    "\n",
    "# # Less frequent observations\n",
    "# config['obs_freq'] = 50\n",
    "# config['DA_freq'] = 50\n",
    "# config['inflate_factor'] = 0.4\n",
    "\n",
    "# # Very infrequent observations\n",
    "# config['obs_freq'] = 200\n",
    "# config['DA_freq'] = 200\n",
    "# config['inflate_factor'] = 0.5\n",
    "\n",
    "# # More frequent observations\n",
    "# config['obs_freq'] = 5\n",
    "# config['DA_freq'] = 5\n",
    "# config['inflate_factor'] = 0.9\n",
    "\n",
    "# # Very frequent observations\n",
    "# config['obs_freq'] = 1\n",
    "# config['DA_freq'] = 1\n",
    "# config['inflate_factor'] = 0.98\n",
    "\n",
    "# # Very frequent observations but less accurate\n",
    "# config['obs_freq'] = 1\n",
    "# config['DA_freq'] = 1\n",
    "# config['obs_sigma'] = 1.0\n",
    "# config['initial_spread'] = 1.0\n",
    "# config['inflate_factor'] = 0.9\n",
    "\n",
    "# # Different time-scale\n",
    "# config['F_fcst'] = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f9183a",
   "metadata": {},
   "source": [
    "The 'real world\" is the Lorenz '96 model:\n",
    "\\begin{align}\n",
    "\\frac{d}{dt} X_k\n",
    "&= - X_{k-1} \\left( X_{k-2} - X_{k+1} \\right) - X_k + F - \\left( \\frac{hc}{b} \\right) \\sum_{j=0}^{J-1} Y_{j,k}\n",
    "\\\\\n",
    "\\frac{d}{dt} Y_{j,k}\n",
    "&= - cbY_{j+1,k} \\left( Y_{j+2,k} - X_{j-1,k} \\right) - c Y_{j,k} + \\frac{hc}{b} X_k\n",
    "\\end{align}\n",
    "\n",
    "The cell below spins-up a state and then records a series of $X$ and $Y$ at time $t$ in arrays `X_truth`, `Y_truth` and `t_truth` respectively. The initial state $X(t=0$ is recorded in `X_init` (and equal to `X_truth[0]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1fd0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the \"truth\" 2-scale L96 model and generate initial conditions from a short spinup\n",
    "M_truth = L96(config[\"K\"], config[\"J\"], F=config[\"F_truth\"], dt=config[\"dt\"])\n",
    "M_truth.set_state(rng.standard_normal((config[\"K\"])), 0 * M_truth.j)\n",
    "X_init, Y_init, _ = M_truth.run(config[\"si\"], config[\"si\"] * config[\"ns_spinup\"])\n",
    "X_init, Y_init = X_init[-1, :], Y_init[-1, :]\n",
    "M_truth.set_state(X_init, Y_init)\n",
    "\n",
    "# Run L96 to generate the \"truth\"\n",
    "X_truth, Y_truth, t_truth = M_truth.run(config[\"si\"], config[\"si\"] * config[\"ns\"])\n",
    "\n",
    "del Y_init  # Not used below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe4d0f7",
   "metadata": {},
   "source": [
    "Now we create some \"observations\" of the \"real world\" by sampling at `obs_freq` intervals and adding some noise (observational error). `X_obs` are the observations at `k=l_obs` positions and `t=t_truth[t_obs]` times. Note that `t_obs` is an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffa2f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample the \"truth\" to generate observations at certain times (t_obs) and locations (l_obs)\n",
    "t_obs = np.tile(\n",
    "    config[\"obs_freq\"] + np.arange(0, config[\"ns_da\"], config[\"obs_freq\"]),\n",
    "    [int(config[\"K\"] * config[\"obs_density\"]), 1],\n",
    ").T\n",
    "l_obs = np.zeros(t_obs.shape, dtype=\"int\")\n",
    "for i in range(l_obs.shape[0]):\n",
    "    l_obs[i, :] = rng.choice(\n",
    "        config[\"K\"], int(config[\"K\"] * config[\"obs_density\"]), replace=False\n",
    "    )\n",
    "X_obs = X_truth[t_obs, l_obs] + config[\"obs_sigma\"] * rng.standard_normal(l_obs.shape)\n",
    "\n",
    "# Calculated observation covariance matrix, assuming independent observations\n",
    "R = config[\"obs_sigma\"] ** 2 * np.eye(int(config[\"K\"] * config[\"obs_density\"]))\n",
    "\n",
    "plt.figure(figsize=[10, 6])\n",
    "plt.plot(t_truth[:], X_truth[:, 0], label=\"truth\")\n",
    "plt.scatter(\n",
    "    t_truth[t_obs[1:, 0]],\n",
    "    find_obs(0, X_obs, t_obs, l_obs, [t_obs[0, 0], t_obs[-1, 0]]),\n",
    "    color=\"k\",\n",
    "    label=\"obs\",\n",
    ")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time t\")\n",
    "plt.ylabel(\"X(t)\")\n",
    "plt.title(\"Observations at k=0\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a5e0ca",
   "metadata": {},
   "source": [
    "We run the model in forward mode for 5000 steps to calculate the background covariance. The model is the \"GCM\" function defined above which integrates forward\n",
    "\\begin{align}\n",
    "\\frac{d}{dt} X_k\n",
    "&= - X_{k-1} \\left( X_{k-2} - X_{k+1} \\right) - X_k + F\n",
    "\\end{align}\n",
    "The absence of the coupling term to the $Y$ equations makes this a model with \"missing physics\" that we hope the Ensemble Kalman Filter will correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9316b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate climatological background covariance for 1-scale L96 model\n",
    "X1_clim, _ = GCM(X_init, config[\"F_fcst\"], config[\"dt\"], 5000)\n",
    "B_clim1 = np.cov(X1_clim.T)\n",
    "del X1_clim\n",
    "\n",
    "# load pre-calculated climatological background covariance matrix from a long simulation\n",
    "# B_clim1=np.load('B_clim_L96s.npy')\n",
    "B_loc, W_clim = cov_loc(B_clim1, loc=config[\"B_loc\"])\n",
    "\n",
    "B_corr1 = np.zeros(B_clim1.shape)\n",
    "for i in range(B_clim1.shape[0]):\n",
    "    for j in range(B_clim1.shape[1]):\n",
    "        B_corr1[i, j] = B_clim1[i, j] / np.sqrt(B_clim1[i, i] * B_clim1[j, j])\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.subplot(131)\n",
    "plt.contourf(B_corr1, cmap=\"bwr\", extend=\"both\", levels=np.linspace(-0.95, 0.95, 20))\n",
    "plt.colorbar()\n",
    "plt.title(\"Background correlation matrix 1-scale L96\")\n",
    "plt.subplot(132)\n",
    "plt.contourf(B_loc)\n",
    "plt.colorbar()\n",
    "plt.title(\"B_loc\")\n",
    "plt.subplot(133)\n",
    "plt.contourf(W_clim)\n",
    "plt.colorbar()\n",
    "plt.title(\"W_clim\")\n",
    "\n",
    "del B_loc  # not used below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a205cf53",
   "metadata": {},
   "source": [
    "This is the actual DA algorithm. It steps through segments of time (\"DA cycles\"), launching an ensemble of short forecasts from the posterior estimate of the preceding segment, each perturbed by noise in their initial condition (inflation).\n",
    "\n",
    "Each ensemble trajectory is stored in `ensX`. The increment added to correct the prior is in `X_inc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58124d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up array to store DA increments\n",
    "X_inc = np.zeros(\n",
    "    (int(config[\"ns_da\"] / config[\"DA_freq\"]), config[\"K\"], config[\"nens\"])\n",
    ")\n",
    "if config[\"DA\"] == \"3DVar\":\n",
    "    X_inc = np.squeeze(X_inc)\n",
    "t_DA = np.zeros(int(config[\"ns_da\"] / config[\"DA_freq\"]))\n",
    "\n",
    "# initialize ensemble with perturbations\n",
    "i_t = 0\n",
    "ensX = (\n",
    "    X_init[None, :, None]\n",
    "    + rng.standard_normal((1, config[\"K\"], config[\"nens\"])) * config[\"initial_spread\"]\n",
    ")\n",
    "X_post = ensX[0, ...]\n",
    "\n",
    "W = W_clim\n",
    "\n",
    "# DA cycles\n",
    "for cycle in np.arange(0, config[\"ns_da\"] / config[\"DA_freq\"], dtype=\"int\"):\n",
    "\n",
    "    # set up array to store model forecast for each DA cycle\n",
    "    ensX_fcst = np.zeros((config[\"DA_freq\"] + 1, config[\"K\"], config[\"nens\"]))\n",
    "\n",
    "    # model forecast for next DA cycle\n",
    "    for n in range(config[\"nens\"]):\n",
    "        ensX_fcst[..., n] = GCM(\n",
    "            X_post[0 : config[\"K\"], n],\n",
    "            config[\"F_fcst\"],\n",
    "            config[\"dt\"],\n",
    "            config[\"DA_freq\"],\n",
    "            config[\"GCM_param\"],\n",
    "        )[0]\n",
    "    i_t = i_t + config[\"DA_freq\"]\n",
    "\n",
    "    # get prior/background from the forecast\n",
    "    X_prior = ensX_fcst[-1, ...]  # get prior from model integration\n",
    "\n",
    "    # call DA\n",
    "    t_DA[cycle] = t_truth[i_t]\n",
    "    if config[\"DA\"] == \"EnKF\":\n",
    "        H = ObsOp(config[\"K\"], l_obs, t_obs, i_t)\n",
    "        # augment state vector with parameters when doing parameter estimation\n",
    "        B_ens = np.cov(X_prior)\n",
    "        B_ens_loc = B_ens * W[0 : config[\"K\"], 0 : config[\"K\"]]\n",
    "        X_post = DA_methods.EnKF(X_prior, X_obs[t_obs == i_t], H, R, B_ens_loc)\n",
    "        X_post[0 : config[\"K\"], :] = DA_methods.ens_inflate(\n",
    "            X_post[0 : config[\"K\"], :],\n",
    "            X_prior[0 : config[\"K\"], :],\n",
    "            config[\"inflate_opt\"],\n",
    "            config[\"inflate_factor\"],\n",
    "        )\n",
    "    elif config[\"DA\"] == \"None\":\n",
    "        X_post = X_prior\n",
    "\n",
    "    if not config[\"DA\"] == \"None\":\n",
    "        X_inc[cycle, ...] = (\n",
    "            np.squeeze(X_post[0 : config[\"K\"], ...]) - X_prior[0 : config[\"K\"], ...]\n",
    "        )  # get current increments\n",
    "        # get posterior info about the estimated parameters\n",
    "\n",
    "    # reset initial conditions for next DA cycle\n",
    "    ensX_fcst[-1, :, :] = X_post[0 : config[\"K\"], :]\n",
    "    ensX = np.concatenate((ensX, ensX_fcst[1:None, ...]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86c2d1c",
   "metadata": {},
   "source": [
    "`meanX` is the ensemble mean forecast, averaging over all the ensemble members. It has discontinuities due to the increment add between each DA segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc0b556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# post processing and visualization\n",
    "meanX = np.mean(ensX, axis=-1)\n",
    "clim = np.max(np.abs(meanX - X_truth[0 : (config[\"ns_da\"] + 1), :]))\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "ch = axes[0, 0].contourf(\n",
    "    M_truth.k,\n",
    "    t_truth[0 : (config[\"ns_da\"] + 1)],\n",
    "    meanX - X_truth[0 : (config[\"ns_da\"] + 1), :],\n",
    "    cmap=\"bwr\",\n",
    "    levels=np.arange(-6.5, 7, 1),\n",
    "    extend=\"both\",\n",
    ")\n",
    "plt.colorbar(ch, ax=axes[0, 0], orientation=\"horizontal\")\n",
    "axes[0, 0].set_xlabel(\"s\")\n",
    "axes[0, 0].set_ylabel(\"t\")\n",
    "axes[0, 0].set_title(\"X - X_truth\")\n",
    "axes[0, 1].plot(\n",
    "    t_truth[0 : (config[\"ns_da\"] + 1)],\n",
    "    np.sqrt(((meanX - X_truth[0 : (config[\"ns_da\"] + 1), :]) ** 2).mean(axis=-1)),\n",
    "    label=\"RMSE\",\n",
    ")\n",
    "axes[0, 1].plot(\n",
    "    t_truth[0 : (config[\"ns_da\"] + 1)],\n",
    "    np.mean(np.std(ensX, axis=-1), axis=-1),\n",
    "    label=\"Spread\",\n",
    ")\n",
    "axes[0, 1].plot(\n",
    "    t_truth[0 : (config[\"ns_da\"] + 1)],\n",
    "    config[\"obs_sigma\"] * np.ones((config[\"ns_da\"] + 1)),\n",
    "    label=\"Obs error\",\n",
    ")\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].set_xlabel(\"time\")\n",
    "axes[0, 1].set_title(\"RMSE (X - X_truth)\")\n",
    "axes[0, 1].grid(which=\"both\", linestyle=\"--\")\n",
    "\n",
    "axes[0, 2].plot(\n",
    "    M_truth.k,\n",
    "    np.sqrt(((meanX - X_truth[0 : (config[\"ns_da\"] + 1), :]) ** 2).mean(axis=0)),\n",
    "    label=\"RMSE\",\n",
    ")\n",
    "X_inc_ave = X_inc / config[\"DA_freq\"] / config[\"si\"]\n",
    "axes[0, 2].plot(M_truth.k, X_inc_ave.mean(axis=(0, -1)), label=\"Inc\")\n",
    "axes[0, 2].plot(\n",
    "    M_truth.k, running_ave(X_inc_ave.mean(axis=(0, -1)), 7), label=\"Inc Ave\"\n",
    ")\n",
    "axes[0, 2].plot(\n",
    "    M_truth.k,\n",
    "    np.ones(M_truth.k.shape) * (config[\"F_fcst\"] - config[\"F_truth\"]),\n",
    "    label=\"F_bias\",\n",
    ")\n",
    "axes[0, 2].plot(\n",
    "    M_truth.k,\n",
    "    np.ones(M_truth.k.shape) * (X_inc / config[\"DA_freq\"] / config[\"si\"]).mean(),\n",
    "    \"k:\",\n",
    "    label=\"Ave Inc\",\n",
    ")\n",
    "axes[0, 2].legend()\n",
    "axes[0, 2].set_xlabel(\"s\")\n",
    "axes[0, 2].set_title(\"Increments\")\n",
    "axes[0, 2].grid(which=\"both\", linestyle=\"--\")\n",
    "\n",
    "# X_inc_ave=(X_inc/config['DA_freq']/config['si']).mean(axis=(1,2)).\\\n",
    "#         reshape(int(config['ns_da']/ann_period),int(ann_period/config['DA_freq'])).mean(axis=0)\n",
    "# axes[0,2].plot(np.arange(ann_period/config['DA_freq']),X_inc_ave,label='Inc')\n",
    "# axes[0,2].plot(np.arange(ann_period/config['DA_freq']),running_ave(X_inc_ave,10),label='Inc Ave');\n",
    "# axes[0,2].plot(np.arange(0,ann_period/config['DA_freq'],mon_period/config['DA_freq']),\n",
    "#                -2*np.sin(2*np.pi*np.arange(mon_per_ann)/mon_per_ann),label='F_bias')\n",
    "# axes[0,2].legend()\n",
    "# axes[0,2].set_xlabel('\"annual cycle\"'); axes[0,2].set_title('Increments');\n",
    "# axes[0,2].grid(which='both',linestyle='--')\n",
    "\n",
    "plot_start, plot_end = 200, 800\n",
    "plot_start_DA, plot_end_DA = int(plot_start / config[\"DA_freq\"]), int(\n",
    "    plot_end / config[\"DA_freq\"]\n",
    ")\n",
    "plot_x = 0\n",
    "axes[1, 0].plot(\n",
    "    t_truth[plot_start:plot_end], X_truth[plot_start:plot_end, plot_x], label=\"truth\"\n",
    ")\n",
    "axes[1, 0].plot(\n",
    "    t_truth[plot_start:plot_end], meanX[plot_start:plot_end, plot_x], label=\"forecast\"\n",
    ")\n",
    "axes[1, 0].scatter(\n",
    "    t_DA[plot_start_DA - 1 : plot_end_DA - 1],\n",
    "    find_obs(plot_x, X_obs, t_obs, l_obs, [plot_start, plot_end]),\n",
    "    label=\"obs\",\n",
    ")\n",
    "axes[1, 0].grid(which=\"both\", linestyle=\"--\")\n",
    "axes[1, 0].set_xlabel(\"time\")\n",
    "axes[1, 0].set_title(\"k=\" + str(plot_x + 1) + \" truth and forecast\")\n",
    "axes[1, 0].legend()\n",
    "\n",
    "axes[1, 2].text(\n",
    "    0.1,\n",
    "    0.1,\n",
    "    \"RMSE={:3f}\\nSpread={:3f}\\nGCM param={}\\nDA={},{}\\nDA_freq={}\\nB_loc={}\\ninflation={},{}\\nobs_density={}\\nobs_sigma={}\\nobs_freq={}\".format(\n",
    "        np.sqrt(((meanX - X_truth[0 : (config[\"ns_da\"] + 1), :]) ** 2).mean()),\n",
    "        np.mean(np.std(ensX, axis=-1)),\n",
    "        config[\"DA\"],\n",
    "        config[\"GCM_param\"],\n",
    "        config[\"nens\"],\n",
    "        config[\"DA_freq\"],\n",
    "        config[\"B_loc\"],\n",
    "        config[\"inflate_opt\"],\n",
    "        config[\"inflate_factor\"],\n",
    "        config[\"obs_density\"],\n",
    "        config[\"obs_sigma\"],\n",
    "        config[\"obs_freq\"],\n",
    "    ),\n",
    "    fontsize=15,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882dc39c",
   "metadata": {},
   "source": [
    "Converting the increment `X_inc` into a tendency, we can examine the relationship between the $\\dot{X}$ due to the missing physics and the state of the model at the beginning of each DA segment. If we are properly correcting the absence of the coupling term then this structure should look like the parameterization of the coupling term, as done in Wilks, 2005."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9506a37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "jj = np.abs(X_inc_ave[0:, :].flatten()) > -1e-7\n",
    "\n",
    "x_input = ensX[t_obs[0:, 0] - config[\"DA_freq\"], :].flatten()[\n",
    "    jj\n",
    "]  # The offset by DA_freq looks at the previous posterior\n",
    "x_input = 0.5 * (\n",
    "    x_input + ensX[t_obs[0:, 0], :].flatten()[jj]\n",
    ")  # Mid-point of trajectory\n",
    "xinc_output = X_inc_ave[0:, :].flatten()[jj]\n",
    "\n",
    "x = np.linspace(-8, 15, 100)\n",
    "p = np.polyfit(x_input, xinc_output, 4)\n",
    "p18 = [0.000707, -0.0130, -0.0190, 1.59, 0.275]  # Polynomial from Wilks, 2005\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.suptitle(\"All time, all individial k, and all ensemble members\")\n",
    "plt.subplot(121)\n",
    "plt.plot(x_input, xinc_output, \"k.\")\n",
    "plt.grid()\n",
    "plt.plot(x, -np.polyval(p18, x), label=\"$P_4(X_k)$ - Wilks, 2005\")\n",
    "plt.plot(x, np.polyval(p, x), label=\"$P_4(X_k)$\")\n",
    "plt.xlabel(\"Ensemble member $X_i(k,t)$\")\n",
    "plt.ylabel(\"Ensemble member increment $\\dot{X}$\")\n",
    "plt.subplot(122)\n",
    "plt.hist2d(\n",
    "    x_input, xinc_output, bins=(np.linspace(-10, 15, 50), np.linspace(-25, 20, 150))\n",
    ")\n",
    "plt.plot(x, -np.polyval(p18, x), label=\"$P_4(X_k)$ - Wilks, 2005\")\n",
    "plt.plot(x, np.polyval(p, x), label=\"$P_4(X_k)$\")\n",
    "plt.xlabel(\"Ensemble member $X_i(k,t)$\")\n",
    "plt.ylabel(\"Ensemble member increment $\\dot{X}$\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5424c07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "jj = np.abs(X_inc_ave.mean(axis=-1).flatten()) > -1e-7\n",
    "\n",
    "x_input = meanX[t_obs[0:, 0] - config[\"DA_freq\"]].flatten()[\n",
    "    jj\n",
    "]  # The offset by DA_freq looks at the previous posterior\n",
    "x_input = 0.5 * (x_input + meanX[t_obs[0:, 0]].flatten()[jj])  # Mid-point of trajectory\n",
    "xinc_output = X_inc_ave.mean(axis=-1).flatten()[jj]\n",
    "\n",
    "x = np.linspace(-8, 15, 100)\n",
    "p = np.polyfit(x_input, xinc_output, 4)\n",
    "p18 = [0.000707, -0.0130, -0.0190, 1.59, 0.275]  # Polynomial from Wilks, 2005\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.suptitle(\"All time, all individial k, mean over ensemble members\")\n",
    "plt.subplot(121)\n",
    "plt.plot(x_input, xinc_output, \"k.\")\n",
    "plt.grid()\n",
    "plt.plot(x, -np.polyval(p18, x), label=\"$P_4(X_k)$ - Wilks, 2005\")\n",
    "plt.plot(x, np.polyval(p, x), label=\"$P_4(X_k)\")\n",
    "plt.xlabel(\"Ensemble member $X_i(k,t)$\")\n",
    "plt.ylabel(\"Ensemble member increment $\\dot{X}$\")\n",
    "plt.subplot(122)\n",
    "plt.hist2d(\n",
    "    x_input, xinc_output, bins=(np.linspace(-10, 15, 50), np.linspace(-25, 20, 150))\n",
    ")\n",
    "plt.plot(x, -np.polyval(p18, x), label=\"$P_4(X_k)$ - Wilks, 2005\")\n",
    "plt.plot(x, np.polyval(p, x), label=\"$P_4(X_k)\")\n",
    "plt.xlabel(\"Ensemble member $X_i(k,t)$\")\n",
    "plt.ylabel(\"Ensemble member increment $\\dot{X}$\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d2232e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xl = 8, 10\n",
    "k = 0\n",
    "si = config[\"DA_freq\"]\n",
    "\n",
    "l = (l_obs == k).max(axis=1)  # True if observation at time t_obs for column k\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.suptitle(\"Ensemble mean, k = %i\" % (k))\n",
    "plt.plot(t_truth, X_truth[:, k], \"--\", label=\"Truth\")\n",
    "plt.fill_between(\n",
    "    t_truth,\n",
    "    meanX[:, k] - ensX[:, k, :].std(axis=-1),\n",
    "    meanX[:, k] + ensX[:, k, :].std(axis=-1),\n",
    "    color=\"grey\",\n",
    "    alpha=0.2,\n",
    "    label=\"Ensemble spread\",\n",
    ")\n",
    "plt.plot(t_truth, meanX[:, k], label=\"Ensemble mean forecast\")\n",
    "plt.plot(\n",
    "    t_truth[t_obs[l, 0]],\n",
    "    meanX[si::si, k][l] - X_inc.mean(axis=-1)[l, k],\n",
    "    \".\",\n",
    "    label=\"Ensemble mean prior\",\n",
    ")\n",
    "plt.plot(t_truth[t_obs[l, 0]], meanX[si::si, k][l], \".\", label=\"Ensemble mean post\")\n",
    "plt.xlim(xl)\n",
    "plt.xlabel(\"Time, t\")\n",
    "plt.ylabel(\"$X(t)$\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2458896d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xl = 8, 10\n",
    "k = 0\n",
    "e = 19\n",
    "si = config[\"DA_freq\"]\n",
    "\n",
    "l = (l_obs == k).max(axis=1)  # True if observation at time t_obs for column k\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.suptitle(\"Ensemble member %i , k = %i\" % (e, k))\n",
    "plt.plot(t_truth, X_truth[:, k], \"--\", label=\"Truth\")\n",
    "plt.plot(t_truth, ensX[:, k, e], label=\"Ensemble member forecast\")\n",
    "plt.plot(\n",
    "    t_truth[t_obs[l, 0]],\n",
    "    ensX[si::si, k, e][l] - X_inc[:, :, e][l, k],\n",
    "    \".\",\n",
    "    label=\"Ensemble member prior\",\n",
    ")\n",
    "plt.plot(t_truth[t_obs[l, 0]], ensX[si::si, k, e][l], \".\", label=\"Ensemble member post\")\n",
    "plt.xlim(xl)\n",
    "plt.xlabel(\"Time, t\")\n",
    "plt.ylabel(\"$X(t)$\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b07e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data for other notebooks to read\n",
    "np.savez(\n",
    "    \"increments.npz\",\n",
    "    ensX=ensX,\n",
    "    X_inc=X_inc,\n",
    "    t_obs=t_obs,\n",
    "    l_obs=l_obs,\n",
    "    t_inc=t_truth[t_obs[:, 0]],\n",
    "    X_truth=X_truth,\n",
    "    Y_truth=Y_truth,\n",
    "    t_truth=t_truth,\n",
    "    X_obs=X_obs,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
