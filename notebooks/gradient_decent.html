
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Neural networks &#8212; Learning Machine Learning with Lorenz-96</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Learning Data Assimilation Increments" href="Learning-DA-increments.html" />
    <link rel="prev" title="Using neural networks for L96 parameterization" href="Neural_network_for_Lorenz96.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/newlogo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Learning Machine Learning with Lorenz-96</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Introduction
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="L96-two-scale-description.html">
   The Lorenz-96 Two-Timescale System
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="gcm-analogue.html">
   The Lorenz-96 GCM Analog
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="gcm-parameterization-problem.html">
   Key aspects of GCMs parameterizations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="estimating-gcm-parameters.html">
   Tuning GCM Parameterizations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="DA_demo_L96.html">
   Data Assimilation demo in the Lorenz 96 (L96) two time-scale model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Neural_network_for_Lorenz96.html">
   Using neural networks for L96 parameterization
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Neural networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Learning-DA-increments.html">
   Learning Data Assimilation Increments
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="random_forest_parameterization.html">
   Random Forest
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Neural-Network-Saliency-Maps.html">
   Generating saliency maps for neural networks trained on L96
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Neural-Network-Advection.html">
   Using neural networks to parameterize advection in L96
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../bibliography.html">
   References
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/notebooks/gradient_decent.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/m2lines/L96_demo"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/m2lines/L96_demo/issues/new?title=Issue%20on%20page%20%2Fnotebooks/gradient_decent.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/m2lines/L96_demo/main?urlpath=tree/notebooks/gradient_decent.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#universal-approximation-theorem-nns-can-approximate-any-continuous-function">
   Universal approximation theorem - NNs can approximate any continuous function.
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#using-gradient-descent-in-linear-regression">
   Using gradient descent in Linear regression
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#linear-regression-from-scratch">
   Linear regression from scratch
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-pytorch-as-defined-at-https-pytorch-org">
     What is pytorch? (as defined at https://pytorch.org/)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#chose-the-true-parameters-we-want-to-learn">
     Chose the true parameters we want to learn.
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#create-some-data-points-x-and-y-which-lie-on-the-line">
     Create some data points x and y which lie on the line
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#l-frac-1-n-sum-i-1-n-y-i-w-0-w-1-x-i-2">
     <span class="math notranslate nohighlight">
      \(L = \frac{1}{n}\sum_{i=1}^n [y_i - (w_0 + w_1 x_i)]^2\)
     </span>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#so-far-we-have-specified-the-model-linear-regression-and-the-evaluation-criteria-or-loss-function-now-we-need-to-handle-optimization-that-is-how-do-we-find-the-best-values-for-weights-w-0-w-1-how-do-we-find-the-best-fitting-linear-regression">
       So far, we have specified the
       <em>
        model
       </em>
       (linear regression) and the
       <em>
        evaluation criteria
       </em>
       (or
       <em>
        loss function
       </em>
       ). Now we need to handle
       <em>
        optimization
       </em>
       ; that is, how do we find the best values for weights (
       <span class="math notranslate nohighlight">
        \(w_0\)
       </span>
       ,
       <span class="math notranslate nohighlight">
        \(w_1\)
       </span>
       )? How do we find the best
       <em>
        fitting
       </em>
       linear regression.
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#if-we-know-those-we-can-iteratively-take-little-steps-down-the-gradient-to-reduce-the-loss-aka-gradient-descent-how-big-our-steps-are-is-determined-by-the-learning-rate">
       If we know those we can iteratively take little steps down the gradient to reduce the loss, aka,
       <em>
        gradient descent
       </em>
       . How big our steps are is determined by the
       <em>
        learning rate
       </em>
       .
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#in-deep-learning-we-use-a-variation-of-gradient-descent-called-mini-batch-gradient-descent">
       In Deep learning, we use a variation of gradient descent called mini-batch gradient descent:
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Neural networks</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#universal-approximation-theorem-nns-can-approximate-any-continuous-function">
   Universal approximation theorem - NNs can approximate any continuous function.
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#using-gradient-descent-in-linear-regression">
   Using gradient descent in Linear regression
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#linear-regression-from-scratch">
   Linear regression from scratch
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-pytorch-as-defined-at-https-pytorch-org">
     What is pytorch? (as defined at https://pytorch.org/)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#chose-the-true-parameters-we-want-to-learn">
     Chose the true parameters we want to learn.
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#create-some-data-points-x-and-y-which-lie-on-the-line">
     Create some data points x and y which lie on the line
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#l-frac-1-n-sum-i-1-n-y-i-w-0-w-1-x-i-2">
     <span class="math notranslate nohighlight">
      \(L = \frac{1}{n}\sum_{i=1}^n [y_i - (w_0 + w_1 x_i)]^2\)
     </span>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#so-far-we-have-specified-the-model-linear-regression-and-the-evaluation-criteria-or-loss-function-now-we-need-to-handle-optimization-that-is-how-do-we-find-the-best-values-for-weights-w-0-w-1-how-do-we-find-the-best-fitting-linear-regression">
       So far, we have specified the
       <em>
        model
       </em>
       (linear regression) and the
       <em>
        evaluation criteria
       </em>
       (or
       <em>
        loss function
       </em>
       ). Now we need to handle
       <em>
        optimization
       </em>
       ; that is, how do we find the best values for weights (
       <span class="math notranslate nohighlight">
        \(w_0\)
       </span>
       ,
       <span class="math notranslate nohighlight">
        \(w_1\)
       </span>
       )? How do we find the best
       <em>
        fitting
       </em>
       linear regression.
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#if-we-know-those-we-can-iteratively-take-little-steps-down-the-gradient-to-reduce-the-loss-aka-gradient-descent-how-big-our-steps-are-is-determined-by-the-learning-rate">
       If we know those we can iteratively take little steps down the gradient to reduce the loss, aka,
       <em>
        gradient descent
       </em>
       . How big our steps are is determined by the
       <em>
        learning rate
       </em>
       .
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#in-deep-learning-we-use-a-variation-of-gradient-descent-called-mini-batch-gradient-descent">
       In Deep learning, we use a variation of gradient descent called mini-batch gradient descent:
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="neural-networks">
<h1>Neural networks<a class="headerlink" href="#neural-networks" title="Permalink to this headline">¶</a></h1>
<div class="section" id="universal-approximation-theorem-nns-can-approximate-any-continuous-function">
<h2>Universal approximation theorem - NNs can approximate any continuous function.<a class="headerlink" href="#universal-approximation-theorem-nns-can-approximate-any-continuous-function" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>A visual demonstration that neural nets can compute any function: http://neuralnetworksanddeeplearning.com/chap4.html</p></li>
<li><p>Like any ML algorithm, training a neural netwoek requires minimizing some loss function (for a given structure that maps inputs to outputs).</p></li>
<li><p>The minimization is done using an algorithm called gradient descent, or a variation called stochastic/minibach gradient descent.</p></li>
</ul>
</div>
<div class="section" id="using-gradient-descent-in-linear-regression">
<h2>Using gradient descent in Linear regression<a class="headerlink" href="#using-gradient-descent-in-linear-regression" title="Permalink to this headline">¶</a></h2>
<p>The simplest machine learning algorithm is linear regression. We will code up linear regression from scratch with a twist: we will use gradient descent, which is also how neural networks learn. Most of this lesson is pretty much stolen from Jeremy Howard’s fast.ai <a class="reference external" href="https://www.youtube.com/watch?v=ACU-T9L4_lI">lesson zero</a></p>
<ul class="simple">
<li><p>In linear regression, we assume that <span class="math notranslate nohighlight">\(y = w_0 + w_1 x \)</span>.</p></li>
<li><p>We look for the <span class="math notranslate nohighlight">\(w\)</span> coefficients that give the ‘best’ prediction for the output (<span class="math notranslate nohighlight">\(y\)</span>). The best prediction is defined by minimizing some cost function. For linear regression in machine learning task it is usually the mean square error.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Image</span>

<span class="n">Image</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="s2">&quot;figs/linear_regression_as_neural_network2.png&quot;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="c1"># Image is taken from https://blog.insightdatascience.com/a-quick-introduction-to-vanilla-neural-networks-b0998c6216a1</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/gradient_decent_5_0.png" src="../_images/gradient_decent_5_0.png" />
</div>
</div>
</div>
<div class="section" id="linear-regression-from-scratch">
<h2>Linear regression from scratch<a class="headerlink" href="#linear-regression-from-scratch" title="Permalink to this headline">¶</a></h2>
<p>We will learn the parameters <span class="math notranslate nohighlight">\(w_0\)</span> and <span class="math notranslate nohighlight">\(\mathbf{w}_1\)</span> of a line.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import plotting packages</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">from</span> <span class="nn">matplotlib.animation</span> <span class="kn">import</span> <span class="n">FuncAnimation</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">HTML</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Import machine-learning packages</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="kn">import</span> <span class="n">Variable</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torch.utils.data</span> <span class="k">as</span> <span class="nn">Data</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">HTML</span>

<span class="c1"># from fastai.basics import *</span>
<span class="kn">from</span> <span class="nn">matplotlib.animation</span> <span class="kn">import</span> <span class="n">FuncAnimation</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>

<span class="c1"># Set random seed for reproducibility</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="what-is-pytorch-as-defined-at-https-pytorch-org">
<h3>What is pytorch? (as defined at https://pytorch.org/)<a class="headerlink" href="#what-is-pytorch-as-defined-at-https-pytorch-org" title="Permalink to this headline">¶</a></h3>
<p>It’s a Python-based scientific computing package targeted at two sets of audiences:</p>
<ul class="simple">
<li><p>A replacement for NumPy to use the power of GPUs</p></li>
<li><p>A deep learning research platform that provides flexibility and speed</p></li>
</ul>
</div>
<div class="section" id="chose-the-true-parameters-we-want-to-learn">
<h3>Chose the true parameters we want to learn.<a class="headerlink" href="#chose-the-true-parameters-we-want-to-learn" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">([</span><span class="mf">3.0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">w</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([3., 2.])
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="create-some-data-points-x-and-y-which-lie-on-the-line">
<h3>Create some data points x and y which lie on the line<a class="headerlink" href="#create-some-data-points-x-and-y-which-lie-on-the-line" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">x</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span>
    <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mi">1</span>
<span class="p">)</span>  <span class="c1"># Underscore functions in pytorch means replace the value (update)</span>
<span class="n">x</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[ 1.0000, -0.1092],
        [ 1.0000, -0.6208],
        [ 1.0000, -0.4135],
        [ 1.0000,  0.4920],
        [ 1.0000, -0.5905]])
</pre></div>
</div>
</div>
</div>
<p>Tensor is a data structure which is a fundamental building block of PyTorch. Tensors are pretty much like numpy arrays, except that unlike numpy, tensors are designed to take advantage of parallel computation capabilities of a GPU
and more importantly for us - they can keep track of its gradients.</p>
<p>For further reading, see <a class="reference external" href="https://blog.paperspace.com/pytorch-101-understanding-graphs-and-automatic-differentiation/">here</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">@</span> <span class="n">w</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>  <span class="c1"># @ is a matrix product (similar to matmul)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/gradient_decent_15_0.png" src="../_images/gradient_decent_15_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">w_real</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">3.0</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>If we could find a way to fit our guess for the coefficients the weights (<span class="math notranslate nohighlight">\(w_0\)</span> and <span class="math notranslate nohighlight">\(\mathbf{w}_1\)</span>), we could use the exact same method for very complicated tasks (as in image recognition).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">mse</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">((</span><span class="n">y_true</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Written in terms of <span class="math notranslate nohighlight">\(w_0\)</span> and <span class="math notranslate nohighlight">\(w_1\)</span>, our <strong>loss function</strong> is:</p>
</div>
<div class="section" id="l-frac-1-n-sum-i-1-n-y-i-w-0-w-1-x-i-2">
<h3><span class="math notranslate nohighlight">\(L = \frac{1}{n}\sum_{i=1}^n [y_i - (w_0 + w_1 x_i)]^2\)</span><a class="headerlink" href="#l-frac-1-n-sum-i-1-n-y-i-w-0-w-1-x-i-2" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_hat</span> <span class="o">=</span> <span class="n">x</span> <span class="o">@</span> <span class="n">w_real</span>
<span class="n">mse</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>  <span class="c1"># Initial mean-squared error</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor(55.0856)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y_hat</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/gradient_decent_21_0.png" src="../_images/gradient_decent_21_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">w</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">w_real</span><span class="p">)</span>
<span class="n">w</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Parameter containing:
tensor([-3., -5.], requires_grad=True)
</pre></div>
</div>
</div>
</div>
<div class="section" id="so-far-we-have-specified-the-model-linear-regression-and-the-evaluation-criteria-or-loss-function-now-we-need-to-handle-optimization-that-is-how-do-we-find-the-best-values-for-weights-w-0-w-1-how-do-we-find-the-best-fitting-linear-regression">
<h4>So far, we have specified the <em>model</em> (linear regression) and the <em>evaluation criteria</em> (or <em>loss function</em>). Now we need to handle <em>optimization</em>; that is, how do we find the best values for weights (<span class="math notranslate nohighlight">\(w_0\)</span>, <span class="math notranslate nohighlight">\(w_1\)</span>)? How do we find the best <em>fitting</em> linear regression.<a class="headerlink" href="#so-far-we-have-specified-the-model-linear-regression-and-the-evaluation-criteria-or-loss-function-now-we-need-to-handle-optimization-that-is-how-do-we-find-the-best-values-for-weights-w-0-w-1-how-do-we-find-the-best-fitting-linear-regression" title="Permalink to this headline">¶</a></h4>
<p>To know how to change <span class="math notranslate nohighlight">\(w_0\)</span> and <span class="math notranslate nohighlight">\(w_1\)</span> to reduce the loss, we compute the derivatives (or gradients).</p>
<p><span class="math notranslate nohighlight">\(\frac{\partial L}{\partial w_0} = \frac{1}{n}\sum_i -2[y_i - (w_0 + w_1 x_i)]\)</span></p>
<p><span class="math notranslate nohighlight">\(\frac{\partial L}{\partial w_1} = \frac{1}{n}\sum_i -2[y_i - (w_0 + w_1 x_i)]x_i\)</span></p>
</div>
<div class="section" id="if-we-know-those-we-can-iteratively-take-little-steps-down-the-gradient-to-reduce-the-loss-aka-gradient-descent-how-big-our-steps-are-is-determined-by-the-learning-rate">
<h4>If we know those we can iteratively take little steps down the gradient to reduce the loss, aka, <em>gradient descent</em>. How big our steps are is determined by the <em>learning rate</em>.<a class="headerlink" href="#if-we-know-those-we-can-iteratively-take-little-steps-down-the-gradient-to-reduce-the-loss-aka-gradient-descent-how-big-our-steps-are-is-determined-by-the-learning-rate" title="Permalink to this headline">¶</a></h4>
<p><span class="math notranslate nohighlight">\(w_0^{new} = w_0^{old}\)</span> - Learning-Rate <span class="math notranslate nohighlight">\(*  \frac{\partial L}{\partial w_0}\)</span></p>
<p><span class="math notranslate nohighlight">\(w_1^{new} = w_1^{old}\)</span> - Learning-Rate <span class="math notranslate nohighlight">\(*  \frac{\partial L}{\partial w_1}\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">update2</span><span class="p">(</span><span class="n">iteration</span><span class="p">):</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">x</span> <span class="o">@</span> <span class="n">w</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">mse</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">)</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="c1"># calculate the gradient of a tensor! It is now stored at w.grad</span>

    <span class="c1"># To prevent tracking history and using memory</span>
    <span class="c1"># (code block where we don&#39;t need to track the gradients but only modify the values of tensors)</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">w</span><span class="o">.</span><span class="n">sub_</span><span class="p">(</span><span class="n">lr</span> <span class="o">*</span> <span class="n">w</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
        <span class="c1"># Under score means inplace.</span>
        <span class="c1"># lr is the learning rate. Good learning rate is a key part of Neural Networks.</span>

        <span class="n">w</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
        <span class="c1"># We want to zero the gradient before we are re-evaluate it.</span>

    <span class="k">return</span> <span class="n">loss</span>
</pre></div>
</div>
</div>
</div>
<p>In PyTorch, we need to set the gradients to zero before starting to do back propragation because PyTorch accumulates the gradients on subsequent backward passes. This is convenient while training RNNs. So, the default action is to accumulate (i.e. sum) the gradients on every loss.backward() call.
Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly. Else the gradient would point in some other direction than the intended direction towards the minimum (or maximum, in case of maximization objectives).</p>
<p>Explanations about how PyTorch calculates the gradients can be found here (and in many other sources) - https://blog.paperspace.com/pytorch-101-understanding-graphs-and-automatic-differentiation/</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">lin</span><span class="p">(</span><span class="n">w1</span><span class="p">,</span> <span class="n">w0</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">w1</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">w0</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">])</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="p">)</span>
<span class="p">(</span><span class="n">line</span><span class="p">,)</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span>
    <span class="n">lin</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="n">w</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">1</span><span class="p">],</span> <span class="n">x</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[:,</span> <span class="mi">0</span><span class="p">]),</span>
    <span class="n">c</span><span class="o">=</span><span class="s2">&quot;firebrick&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="c1"># line, = ax.plot(x[:,0], y, c=&#39;firebrick&#39;)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Loss = 0.00&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">animate</span><span class="p">(</span><span class="n">i</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
        <span class="n">l</span> <span class="o">=</span> <span class="n">update2</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Loss = </span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">l</span><span class="p">)</span>
    <span class="n">line</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span>
        <span class="n">x</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[:,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="n">lin</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="n">w</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">1</span><span class="p">],</span> <span class="n">x</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[:,</span> <span class="mi">0</span><span class="p">]),</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">line</span><span class="p">,)</span>


<span class="n">anim</span> <span class="o">=</span> <span class="n">FuncAnimation</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">animate</span><span class="p">,</span> <span class="n">frames</span><span class="o">=</span><span class="mi">70</span><span class="p">,</span> <span class="n">interval</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span> <span class="n">blit</span><span class="o">=</span><span class="kc">True</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># You might have some difficulties running this cell without importing certain packages.</span>
<span class="c1"># might need to install: conda install -c conda-forge ffmpeg</span>
<span class="n">HTML</span><span class="p">(</span><span class="n">anim</span><span class="o">.</span><span class="n">to_html5_video</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><video width="720" height="432" controls autoplay loop>
  <source type="video/mp4" src="data:video/mp4;base64,AAAAIGZ0eXBNNFYgAAACAE00ViBpc29taXNvMmF2YzEAAAAIZnJlZQAAJaptZGF0AAACrgYF//+q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==
">
  Your browser does not support the video tag.
</video></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Image</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="s2">&quot;figs/Gradient_descent2.png&quot;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">700</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/gradient_decent_29_0.png" src="../_images/gradient_decent_29_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">])</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">update2</span><span class="p">(</span><span class="n">t</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">losses</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Iternation&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0, 0.5, &#39;Loss&#39;)
</pre></div>
</div>
<img alt="../_images/gradient_decent_30_1.png" src="../_images/gradient_decent_30_1.png" />
</div>
</div>
</div>
<div class="section" id="in-deep-learning-we-use-a-variation-of-gradient-descent-called-mini-batch-gradient-descent">
<h4>In Deep learning, we use a variation of gradient descent called <a class="reference external" href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/">mini-batch gradient descent</a>:<a class="headerlink" href="#in-deep-learning-we-use-a-variation-of-gradient-descent-called-mini-batch-gradient-descent" title="Permalink to this headline">¶</a></h4>
<p>Instead of calculating the gradient over the whole training data before changing model weights (coefficients), we take a subset (batch) of our data, and change the values of the weights after we calculated the gradient over this subset.</p>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="Neural_network_for_Lorenz96.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Using neural networks for L96 parameterization</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="Learning-DA-increments.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Learning Data Assimilation Increments</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By The M2LinES Community<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>